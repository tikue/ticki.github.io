<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algorithms on Ticki&#39;s blog</title>
    <link>http://ticki.github.io/tags/algorithms/</link>
    <description>Recent content in Algorithms on Ticki&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Dec 2016 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://ticki.github.io/tags/algorithms/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The Eudex Algorithm</title>
      <link>http://ticki.github.io/blog/the-eudex-algorithm/</link>
      <pubDate>Sun, 11 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>http://ticki.github.io/blog/the-eudex-algorithm/</guid>
      <description>Half a year ago, I designed Eudex as a modern replacement for Soundex, which is still widely used today. Eudex supports a wide range of special-cases of European languages, while preserving the spirit of simplicity, Soundex has.
Both Eudex and Soundex are phonetic algorithms that produce a representation of the sound of some string. Eudex is fundamentally different from Soundex in that it is not a phonetic classifier. It is a phonetic locality-sensitive hash, which means that two similarly-sounding strings are not mapped to the same value, but instead to values near to each other.</description>
    </item>
    
    <item>
      <title>SeaHash: Explained</title>
      <link>http://ticki.github.io/blog/seahash-explained/</link>
      <pubDate>Thu, 08 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>http://ticki.github.io/blog/seahash-explained/</guid>
      <description>So, not so long ago, I designed SeaHash, an alternative hash algorithm with performance better than most (all?) of the existing non-cryptographic hash functions available. I designed it for checksumming for a file system, I&#39;m working on, but I quickly found out it was sufficient for general hashing.
It blew up. I got a lot of cool feedback, and yesterday it was picked as crate of the week. It shows that there is some interest in it, so I want to explain the ideas behind it.</description>
    </item>
    
    <item>
      <title>Designing a good non-cryptographic hash function</title>
      <link>http://ticki.github.io/blog/designing-a-good-non-cryptographic-hash-function/</link>
      <pubDate>Fri, 04 Nov 2016 16:28:44 +0200</pubDate>
      
      <guid>http://ticki.github.io/blog/designing-a-good-non-cryptographic-hash-function/</guid>
      <description>So, I&#39;ve been needing a hash function for various purposes, lately. None of the existing hash functions I could find were sufficient for my needs, so I went and designed my own. These are my notes on the design of hash functions.
What is a hash function really? Hash functions are functions which maps a infinite domain to a finite codomain. Two elements in the domain, \(a, b\) are said to collide if \(h(a) = h(b)\).</description>
    </item>
    
    <item>
      <title>How LZ4 works</title>
      <link>http://ticki.github.io/blog/how-lz4-works/</link>
      <pubDate>Tue, 25 Oct 2016 23:25:15 +0200</pubDate>
      
      <guid>http://ticki.github.io/blog/how-lz4-works/</guid>
      <description>LZ4 is a really fast compression algorithm with a reasonable compression ratio, but unfortunately there is limited documentation on how it works. The only explanation (not spec, explanation) can be found on the author&#39;s blog, but I think it is less of an explanation and more of an informal specification.
This blog post tries to explain it such that anybody (even new beginners) can understand and implement it.
Linear small-integer code (LSIC) The first part of LZ4 we need to explain is a smart but simple integer encoder.</description>
    </item>
    
    <item>
      <title>On Random-Access Compression</title>
      <link>http://ticki.github.io/blog/on-random-access-compression/</link>
      <pubDate>Sun, 23 Oct 2016 23:25:15 +0200</pubDate>
      
      <guid>http://ticki.github.io/blog/on-random-access-compression/</guid>
      <description>This post will contains an algorithm I came up with, doing efficient rolling compression. It&#39;s going to be used in TFS.
What is rolling compression? Consider that you have a large file and you want to compress it. That&#39;s easy enough and many algorithms exists for doing so. Now, consider that you want to read or write a small part of the file.
Most algorithms would require you to decompress, write, and recompress the whole file.</description>
    </item>
    
    <item>
      <title>Skip Lists: Done Right</title>
      <link>http://ticki.github.io/blog/skip-lists-done-right/</link>
      <pubDate>Sat, 17 Sep 2016 13:46:49 +0200</pubDate>
      
      <guid>http://ticki.github.io/blog/skip-lists-done-right/</guid>
      <description>What is a skip list? In short, skip lists are a linked-list-like structure which allows for fast search. It consists of a base list holding the elements, together with a tower of lists maintaining a linked hierarchy of subsequences, each skipping over fewer elements.
Skip list is a wonderful data structure, one of my personal favorites, but a trend in the past ten years has made them more and more uncommon as a single-threaded in-memory structure.</description>
    </item>
    
  </channel>
</rss>